{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a594123-527f-4dbb-b927-657a173c5eb0",
      "metadata": {
        "tags": [],
        "id": "0a594123-527f-4dbb-b927-657a173c5eb0"
      },
      "outputs": [],
      "source": [
        "# !pip install ISLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b957fb-64a1-4d7e-bbd3-2fdd3d3e1adb",
      "metadata": {
        "tags": [],
        "id": "f7b957fb-64a1-4d7e-bbd3-2fdd3d3e1adb"
      },
      "outputs": [],
      "source": [
        "#basic imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#preprossing imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#model development imports\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import MultinomialNB as MNB\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "from ISLP import confusion_table as ct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4270a030-d1c4-4b01-bd77-6a0b55cef15b",
      "metadata": {
        "tags": [],
        "id": "4270a030-d1c4-4b01-bd77-6a0b55cef15b"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('/content/sample_data/Dry_Bean_Dataset.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wotqSPvG9Q7c"
      },
      "id": "wotqSPvG9Q7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "840e4d4c-a5a2-49aa-8b18-078cdf8ff2c0",
      "metadata": {
        "tags": [],
        "id": "840e4d4c-a5a2-49aa-8b18-078cdf8ff2c0"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1090dde2-fee8-46b0-af3f-b191906ec9a1",
      "metadata": {
        "tags": [],
        "id": "1090dde2-fee8-46b0-af3f-b191906ec9a1"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3d99d2-05f9-4a7a-9e08-b630e1fba3b5",
      "metadata": {
        "tags": [],
        "id": "2e3d99d2-05f9-4a7a-9e08-b630e1fba3b5"
      },
      "outputs": [],
      "source": [
        "null_values = data.isnull().sum()\n",
        "null_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45650d77-bb1d-4ae3-8be5-6f7d0727998b",
      "metadata": {
        "tags": [],
        "id": "45650d77-bb1d-4ae3-8be5-6f7d0727998b"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d002c3-481f-4ec9-a274-6a48f9f0976b",
      "metadata": {
        "tags": [],
        "id": "99d002c3-481f-4ec9-a274-6a48f9f0976b"
      },
      "outputs": [],
      "source": [
        "# data.info()\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b74d9c5f-e6d6-4cf7-92c4-dfae90f0f940",
      "metadata": {
        "id": "b74d9c5f-e6d6-4cf7-92c4-dfae90f0f940"
      },
      "outputs": [],
      "source": [
        "#Preprossing steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8091ced2-90a4-4cf5-a887-58cdc928fc24",
      "metadata": {
        "tags": [],
        "id": "8091ced2-90a4-4cf5-a887-58cdc928fc24"
      },
      "outputs": [],
      "source": [
        "#replacing class data with values\n",
        "set(data['Class'])\n",
        "encoder = LabelEncoder()\n",
        "data['Class'] = encoder.fit_transform(data['Class'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03be704c-132d-42a0-bcd2-749b2b8c9364",
      "metadata": {
        "tags": [],
        "id": "03be704c-132d-42a0-bcd2-749b2b8c9364"
      },
      "outputs": [],
      "source": [
        "mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
        "mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53730806-2cee-4f48-a7f9-3350716f4a16",
      "metadata": {
        "tags": [],
        "id": "53730806-2cee-4f48-a7f9-3350716f4a16"
      },
      "outputs": [],
      "source": [
        "# tried mim max scaler as well but not able to scale well since variance is very high\n",
        "scaler = RobustScaler()\n",
        "features = data.columns.drop(['Class' , 'Solidity' , 'ShapeFactor2' , 'ShapeFactor4' , 'ShapeFactor3'])\n",
        "data[features] = scaler.fit_transform(data[features])\n",
        "\n",
        "# to make data +ve\n",
        "for col in data:\n",
        "    if data[col].min() < 0:\n",
        "        data[col] += abs(data[col].min())\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8cfeec-40c2-4261-94e6-1d68ff30a195",
      "metadata": {
        "tags": [],
        "id": "6c8cfeec-40c2-4261-94e6-1d68ff30a195"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4264a7d-047e-4d73-87a9-8398b1e03ce4",
      "metadata": {
        "tags": [],
        "id": "c4264a7d-047e-4d73-87a9-8398b1e03ce4"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data['Area'] ,data['Class'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6034bbac-8b27-48a8-8c8a-f4fc3f469761",
      "metadata": {
        "tags": [],
        "id": "6034bbac-8b27-48a8-8c8a-f4fc3f469761"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2699e4ac-0dd4-499c-aba5-190015f0130f",
      "metadata": {
        "tags": [],
        "id": "2699e4ac-0dd4-499c-aba5-190015f0130f"
      },
      "outputs": [],
      "source": [
        "# selected_features = ['Extent',\n",
        "#        'Solidity', 'roundness', 'Compactness', 'ShapeFactor1','Class']\n",
        "# sub_Data = data[selected_features]\n",
        "# type(sub_Data)\n",
        "# sns.pairplot(sub_Data, hue='Class', kind='scatter') # very cost heavy process\n",
        "# data\n",
        "\n",
        "\n",
        "# df_long = data.melt(id_vars=['Class'], var_name='Feature')\n",
        "# df_long\n",
        "# Plot categorical scatter plot of each feature against 'Class'\n",
        "# sns.catplot(data=df_long, x='Class', y='value', hue='Feature', kind='swarm') # cost heavy operation\n",
        "\n",
        "\n",
        "# pred = data[data.columns.drop(['Class'])]\n",
        "# label = data['Class']\n",
        "# type(pred) # may be i should do after some steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02a1d3a8-1354-40a4-8901-507be5a86e1a",
      "metadata": {
        "tags": [],
        "id": "02a1d3a8-1354-40a4-8901-507be5a86e1a"
      },
      "outputs": [],
      "source": [
        "#outliers\n",
        "orf = ['ShapeFactor2','MajorAxisLength', 'Eccentricity','Solidity'] # outliers_removal_features , i plotted scatter to see weather outliers are present or not\n",
        "z_scores = (data[orf] - data[orf].mean()) / data[orf].std()\n",
        "limiter = 5\n",
        "data = data[(z_scores.abs() < limiter).all(axis=1)]\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f735a550-7eca-4cc2-93ec-0d562550959d",
      "metadata": {
        "tags": [],
        "id": "f735a550-7eca-4cc2-93ec-0d562550959d"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce740a54-e51a-4835-99cd-572154e0bb82",
      "metadata": {
        "tags": [],
        "id": "ce740a54-e51a-4835-99cd-572154e0bb82"
      },
      "outputs": [],
      "source": [
        "# plt.scatter(data['Eccentricity'] ,data['Class'] )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = data.columns[:-1]\n",
        "\n",
        "for feature in features:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(x=feature, y='Class', data=data, alpha=0.5)\n",
        "    # sns.lineplot(x=feature, y='Class', data=data.groupby(feature)['Class'].mean(), color='red')\n",
        "    plt.title(f'Scatter and Line Plot for {feature} vs. Class')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Class')\n",
        "    plt.grid(True)\n",
        "\n"
      ],
      "metadata": {
        "id": "IJcJFDypupl1"
      },
      "id": "IJcJFDypupl1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.pairplot(data, hue='Class', diag_kind='kde') # very cost heavy process"
      ],
      "metadata": {
        "id": "TvdW5DNpxUOl"
      },
      "id": "TvdW5DNpxUOl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(1)"
      ],
      "metadata": {
        "id": "OKIqmmg0AAN1"
      },
      "id": "OKIqmmg0AAN1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bad way to edit data\n",
        "# names=['AR/ECC', 'AR/PE/MA/ED/CA', 'CO/SF3']\n",
        "# features = ['AspectRation', 'Eccentricity', 'Area', 'Perimeter', 'MajorAxisLength', 'EquivDiameter', 'ConvexArea', 'Compactness', 'ShapeFactor3']\n",
        "\n",
        "\n",
        "# combined_feature = data[['AspectRation' ,'Eccentricity' ]].mean(axis = 1)\n",
        "# data['Ar/Ecc'] = combined_feature\n",
        "\n",
        "# combined_feature2 = data[[ 'Area', 'Perimeter', 'MajorAxisLength', 'EquivDiameter', 'ConvexArea' ]].mean(axis = 1)\n",
        "# data['AR/PE/MA/ED/CA'] = combined_feature2\n",
        "\n",
        "# combined_feature3 = data[['Compactness', 'ShapeFactor3' ]].mean(axis = 1)\n",
        "# data['CO/SF3'] = combined_feature3\n",
        "\n",
        "# data.drop(['AspectRation', 'Eccentricity', 'Area', 'Perimeter', 'MajorAxisLength', 'EquivDiameter', 'ConvexArea', 'Compactness', 'ShapeFactor3'] , axis=1,inplace=True)\n",
        "# data.head()\n",
        "\n",
        "\n",
        "# bad way to modify\n",
        "\n",
        "# # Define the combine_features function\n",
        "# def combine_features(X):\n",
        "#     combined_features = []\n",
        "#     combined_features.append(X[['AspectRation', 'Eccentricity']].mean(axis=1))\n",
        "#     combined_features.append(X[['Area', 'Perimeter', 'MajorAxisLength', 'EquivDiameter', 'ConvexArea']].mean(axis=1))\n",
        "#     combined_features.append(X[['Compactness', 'ShapeFactor3']].mean(axis=1))\n",
        "#     return pd.concat(combined_features, axis=1)\n",
        "\n",
        "# names=['AR/ECC', 'AR/PE/MA/ED/CA', 'CO/SF3']\n",
        "\n",
        "# # Define the combined_feature_transformer\n",
        "# combined_feature_transformer = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('combine', FunctionTransformer(validate=False), ['AspectRation', 'Eccentricity', 'Area', 'Perimeter', 'MajorAxisLength', 'EquivDiameter', 'ConvexArea', 'Compactness', 'ShapeFactor3'])\n",
        "#     ],\n",
        "#     remainder='passthrough'\n",
        "# )\n",
        "\n",
        "# # Define the pipeline\n",
        "# pipeline = Pipeline([\n",
        "#     ('combine_features', combined_feature_transformer)\n",
        "# ])\n",
        "\n",
        "# # Fit and transform the pipeline\n",
        "# combined_features = pipeline.fit_transform(df)\n",
        "\n",
        "\n",
        "# df_combined = pd.DataFrame(combined_features, index=df.index, names=['AR/ECC', 'AR/PE/MA/ED/CA', 'CO/SF3'])\n",
        "# print(df_combined)\n"
      ],
      "metadata": {
        "id": "-fXs0nRa1ZLD"
      },
      "id": "-fXs0nRa1ZLD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data2 = data.copy()\n",
        "features = ['AspectRation', 'Eccentricity', 'Area', 'Perimeter', 'MajorAxisLength', 'EquivDiameter', 'ConvexArea', 'Compactness', 'ShapeFactor3']\n",
        "names = ['AR/ECC', 'AR/PE/MA/ED/CA', 'CO/SF3']\n",
        "\n",
        "\n",
        "combined_features_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "for name, feature_group in zip(names, [features[:2], features[2:7], features[7:]]):\n",
        "    combined_feature = data[feature_group].mean(axis=1)\n",
        "    combined_features_df[name] = combined_feature\n",
        "\n",
        "combined_features_df\n",
        "\n",
        "data = pd.concat([data , pd.DataFrame(combined_features_df)] , axis = 1 )\n",
        "data.drop(['AspectRation', 'Eccentricity', 'Area', 'Perimeter', 'MajorAxisLength', 'EquivDiameter', 'ConvexArea', 'Compactness', 'ShapeFactor3'] , axis=1,inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "U3ZqWujfcP07"
      },
      "id": "U3ZqWujfcP07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to shift Y(class) to right\n",
        "col = data.pop('Class')\n",
        "data['Class'] = col\n",
        "# data.head(1)\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "dlmIL05bgqVQ"
      },
      "id": "dlmIL05bgqVQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<------------------------------ Preprocessing Part Done ----------------------------->"
      ],
      "metadata": {
        "id": "_GyovQhn0I9o"
      },
      "id": "_GyovQhn0I9o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Certainly! Here's the breakdown:\n",
        "\n",
        "## Using scikit-learn (sklearn):\n",
        "\n",
        "Supervised methods:\n",
        "- Logistic Regression\n",
        "- KNN (K-Nearest Neighbors)\n",
        "- LDA (Linear Discriminant Analysis)\n",
        "- QDA (Quadratic Discriminant Analysis)\n",
        "- Decision Trees\n",
        "- Naive Bayes\n",
        "\n",
        "Unsupervised methods:\n",
        "- K-Means Clustering\n",
        "- Hierarchical Clustering\n",
        "\n",
        "## Using TensorFlow (tf):\n",
        "\n",
        "Supervised methods:\n",
        "\n",
        "- SVM (Support Vector Machines)\n",
        "- Neural Network"
      ],
      "metadata": {
        "id": "nk1VBUjd7fsQ"
      },
      "id": "nk1VBUjd7fsQ"
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating no of features\n",
        "for i in range(7):\n",
        "  print(i ,'count :' ,(data['Class'] == i).sum() )"
      ],
      "metadata": {
        "id": "F-zX1x2A4iGh"
      },
      "id": "F-zX1x2A4iGh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[data.columns.drop('Class')]\n",
        "y = data['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MR6XGpvUO1Fj"
      },
      "id": "MR6XGpvUO1Fj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "U7RBVNhtS49L"
      },
      "id": "U7RBVNhtS49L"
    },
    {
      "cell_type": "code",
      "source": [
        "#100 iteration gives same accuracy as 1lakh iterations\n",
        "logistic_reg = LogisticRegression(max_iter=100, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "\n",
        "logistic_reg.fit(X_train, y_train)\n",
        "y_pred = logistic_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "# print(conf_matrix)\n",
        "ct(y_pred,y_test) # islp package shows good confusion table"
      ],
      "metadata": {
        "id": "85Aq_rZ-P3lv"
      },
      "id": "85Aq_rZ-P3lv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "_jih-TPPY2HM"
      },
      "id": "_jih-TPPY2HM"
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_neigh = 15 # no of neighbours\n",
        "knn = KNeighborsClassifier(n_neighbors=no_of_neigh)\n",
        "knn.fit(X_train , y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "ct(y_test , y_pred_knn)"
      ],
      "metadata": {
        "id": "p2ewTfdqTDrl"
      },
      "id": "p2ewTfdqTDrl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Discriminant Analysis"
      ],
      "metadata": {
        "id": "dFtUQwgJaaMD"
      },
      "id": "dFtUQwgJaaMD"
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LDA()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_lda = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lda))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lda))\n",
        "\n",
        "ct(y_test , y_pred_lda)"
      ],
      "metadata": {
        "id": "NqpU6frDY5Ej"
      },
      "id": "NqpU6frDY5Ej",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qlf = QDA()\n",
        "qlf.fit(X_train, y_train)\n",
        "y_pred_qda = qlf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_qda))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_qda))\n",
        "\n",
        "ct(y_test , y_pred_qda)"
      ],
      "metadata": {
        "id": "iYSv03FQaYkn"
      },
      "id": "iYSv03FQaYkn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees"
      ],
      "metadata": {
        "id": "Tuk_MABAeglr"
      },
      "id": "Tuk_MABAeglr"
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree = tree.DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train , y_train)\n",
        "y_pred_decTree = decision_tree.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_decTree))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_decTree))\n",
        "\n",
        "ct(y_test , y_pred_decTree)"
      ],
      "metadata": {
        "id": "yjomLRtQbabi"
      },
      "id": "yjomLRtQbabi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "PBDLvE74djUY"
      },
      "id": "PBDLvE74djUY"
    },
    {
      "cell_type": "code",
      "source": [
        "naive_model = MNB()\n",
        "naive_model.fit(X_train,y_train)\n",
        "y_pred_nb = naive_model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "ct(y_test , y_pred_nb)"
      ],
      "metadata": {
        "id": "MSg9a8HFcqvo"
      },
      "id": "MSg9a8HFcqvo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QN3UM8qIdohc"
      },
      "id": "QN3UM8qIdohc"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A9RQGC14doI1"
      },
      "id": "A9RQGC14doI1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}